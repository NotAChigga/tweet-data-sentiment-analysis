{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RLPD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfCdtFcYGqtsbVXlQJJ31m"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61tc6sZ8UeDi"
      },
      "source": [
        "1. Install all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJqLQBkUobzU"
      },
      "source": [
        "!pip install textblob\n",
        "!pip install tweepy\n",
        "!pip install matplotlib\n",
        "!pip install emojis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn70eItQUsaG"
      },
      "source": [
        "2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbvUa4oIBTPz"
      },
      "source": [
        "import tweepy\n",
        "import json\n",
        "import emojis\n",
        "import datetime as d\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import textblob as tb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgkQFy9ZUwta"
      },
      "source": [
        "3. API credentials and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7PBJckBiNX"
      },
      "source": [
        "consumer_key = \"###\"\n",
        "consumer_secret = \"###\"\n",
        "access_token = \"###\"\n",
        "access_token_secret = \"###\"\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJXUsxbBU9QB"
      },
      "source": [
        "4. Parameter and data extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds160EZbB2Rg"
      },
      "source": [
        "text_query = '###'\n",
        "language = 'en'\n",
        "count = 2000\n",
        "end_date = d.datetime(2021, 4, 6)\n",
        "\n",
        "searchedTw = [status for status in tweepy.Cursor(api.search, q = text_query, lang =l anguage, until = end_date).items(max_tweets)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biae1vfAVKR5"
      },
      "source": [
        "5. Turn the extracted data into JSON format and decode the emojis into string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYMffpN2XKnI"
      },
      "source": [
        "dict_list = []\n",
        "for each_json_tweet in searchedTw:\n",
        "  dict_list.append(each_json_tweet._json)\n",
        "\n",
        "with open('tweet_json_Data.txt', 'w') as file: \n",
        "  file.write(json.dumps(dict_list,indent=4))\n",
        "\n",
        "demo_list = []\n",
        "with open('tweet_json_Data.txt', encoding = 'utf-8') as json_file:\n",
        "  all_data = json.load(json_file)\n",
        "  for each_dictionary in all_data:\n",
        "    tweet_id = each_dictionary['id']\n",
        "    text = each_dictionary['text']\n",
        "    created_at = each_dictionary['created_at']\n",
        "    demo_list.append({'tweet_id':str(tweet_id), 'text':emojis.decode(str(text)), 'created_at':str(created_at)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6AaQUulVs2a"
      },
      "source": [
        "6. Integrating datas into data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqeJEs1mXuG3"
      },
      "source": [
        "tweet_df = pd.DataFrame(demo_list,columns = ['tweet_id', 'text', 'created_at'])\n",
        "\n",
        "tweet_df.to_csv('tweet_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgZmYnf5WGWQ"
      },
      "source": [
        "7. Data cleaning and sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9bZQN6AF_pB"
      },
      "source": [
        "df = pd.read_csv('tweet_data.csv')\n",
        "def remove_pattern(input_txt, pattern):\n",
        "  r = re.findall(pattern, input_txt)\n",
        "  for i in r:\n",
        "    input_txt = re.sub(i, '', input_txt)\n",
        "      \n",
        "  return input_txt \n",
        "\n",
        "df['text'] = np.vectorize(remove_pattern)(df['text'], \"@[\\w]*\")\n",
        "df['text'] = np.vectorize(remove_pattern)(df['text'], \"RT\")\n",
        "df['text'] = np.vectorize(remove_pattern)(df['text'], \"#\")\n",
        "df['text'] = np.vectorize(remove_pattern)(df['text'], \":\")\n",
        "df['polarity'] = df.apply(lambda x: tb.TextBlob(x['text']).sentiment.polarity, axis = 1)\n",
        "df['polarity'] = df['polarity'].astype(float)\n",
        "\n",
        "df.to_csv('tweet_data_processed.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}